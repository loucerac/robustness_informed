{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.sc-best-practices.org/conditions/gsea_pathway.html#id380\n",
    "# Kang HM, Subramaniam M, Targ S, et al. Multiplexed droplet single-cell RNA-sequencing using natural genetic variation\n",
    "#   Nat Biotechnol. 2020 Nov;38(11):1356]. Nat Biotechnol. 2018;36(1):89-94. doi:10.1038/nbt.4042"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "model_kind = \"ivae_kegg\"\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import scanpy as sc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from ivae_scorer.datasets import load_kang\n",
    "from tensorflow.keras import callbacks\n",
    "import shutil\n",
    "from ivae_scorer.utils import set_all_seeds\n",
    "from ivae_scorer.bio import (\n",
    "    get_adj_matrices,\n",
    "    sync_gexp_adj,\n",
    "    build_hipathia_renamers,\n",
    "    get_reactome_adj,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dotenv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import weightedtau\n",
    "import keras.metrics\n",
    "\n",
    "\n",
    "project_path = Path(dotenv.find_dotenv()).parent\n",
    "results_path = project_path.joinpath(\"results\")\n",
    "results_path.mkdir(exist_ok=True, parents=True)\n",
    "data_path = project_path.joinpath(\"data\")\n",
    "data_path.mkdir(exist_ok=True, parents=True)\n",
    "figs_path = results_path.joinpath(\"figs\")\n",
    "figs_path.mkdir(exist_ok=True, parents=True)\n",
    "tables_path = results_path.joinpath(\"tables\")\n",
    "tables_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "set_all_seeds(seed=42)\n",
    "\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "sc.set_figure_params(dpi=300, color_map=\"inferno\")\n",
    "sc.settings.verbosity = 1\n",
    "sc.logging.print_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    N_EPOCHS = 2\n",
    "    N_ITERS = 10\n",
    "else:\n",
    "    N_EPOCHS = 300\n",
    "    N_ITERS = 100\n",
    "\n",
    "if model_kind == \"ivae_kegg\":\n",
    "    n_encoding_layers = 3\n",
    "elif model_kind == \"ivae_reactome\":\n",
    "    n_encoding_layers = 2\n",
    "else:\n",
    "    raise NotImplementedError(f\"{model_kind} not implemented yet.\")\n",
    "\n",
    "print(f\"{debug=} {model_kind=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = load_kang(data_folder=data_path, normalize=True, n_genes=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trans = adata.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_adj, circuit_to_pathway_adj = get_adj_matrices(\n",
    "    gene_list=x_trans.columns.to_list()\n",
    ")\n",
    "\n",
    "circuit_renamer, pathway_renamer, circuit_to_effector = build_hipathia_renamers()\n",
    "\n",
    "kegg_circuit_names = circuit_adj.rename(columns=circuit_renamer).columns\n",
    "\n",
    "kegg_pathway_names = circuit_to_pathway_adj.rename(columns=pathway_renamer).columns\n",
    "\n",
    "circuit_adj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactome = get_reactome_adj()\n",
    "reactome_pathway_names = reactome.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_kind == \"ivae_kegg\":\n",
    "    x_trans, circuit_adj = sync_gexp_adj(gexp=x_trans, adj=circuit_adj)\n",
    "elif model_kind == \"ivae_reactome\":\n",
    "    x_trans, reactome = sync_gexp_adj(x_trans, reactome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ivae_scorer.models import build_kegg_vae, build_reactome_vae\n",
    "\n",
    "\n",
    "def get_importances(data, abs=False):\n",
    "    if abs:\n",
    "        return np.abs(data).mean(axis=0)\n",
    "    else:\n",
    "        return data.mean(axis=0)\n",
    "\n",
    "\n",
    "def get_activations(act_model, layer_id, data):\n",
    "    data_encoded = act_model.predict(data)[layer_id]\n",
    "    return data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(features, val_size, test_size, stratify, seed):\n",
    "    train_size = 1 - (val_size + test_size)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        features,\n",
    "        stratify,\n",
    "        train_size=train_size,\n",
    "        stratify=stratify,\n",
    "        random_state=seed,\n",
    "    )\n",
    "\n",
    "    x_val, x_test = train_test_split(\n",
    "        x_test,\n",
    "        test_size=test_size / (test_size + val_size),\n",
    "        stratify=y_test,\n",
    "        random_state=seed,\n",
    "    )\n",
    "\n",
    "    x_train = x_train.astype(\"float32\")\n",
    "    x_val = x_val.astype(\"float32\")\n",
    "    x_test = x_test.astype(\"float32\")\n",
    "\n",
    "    return x_train, x_val, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path_model = results_path.joinpath(model_kind)\n",
    "obs = adata.obs.copy()\n",
    "\n",
    "if results_path_model.exists():\n",
    "    shutil.rmtree(results_path_model)\n",
    "results_path_model.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in range(N_ITERS):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    x_train, x_val, x_test = train_val_test_split(\n",
    "        x_trans.apply(minmax_scale),\n",
    "        val_size=0.20,\n",
    "        test_size=0.20,\n",
    "        stratify=obs[\"cell_type\"].astype(str) + obs[\"condition\"].astype(str),\n",
    "        seed=42,\n",
    "    )\n",
    "\n",
    "    if model_kind == \"ivae_kegg\":\n",
    "        vae, encoder, decoder = build_kegg_vae(\n",
    "            circuits=circuit_adj, pathways=circuit_to_pathway_adj, seed=seed\n",
    "        )\n",
    "    elif model_kind == \"ivae_reactome\":\n",
    "        vae, encoder, decoder = build_reactome_vae(reactome, seed=seed)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Model not yet implemented.\")\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    callback = callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",  # Stop training when `val_loss` is no longer improving\n",
    "        min_delta=1e-1,  # \"no longer improving\" being defined as \"no better than 1e-5 less\"\n",
    "        patience=100,  # \"no longer improving\" being further defined as \"for at least 3 epochs\"\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    history = vae.fit(\n",
    "        x_train.values,\n",
    "        shuffle=True,\n",
    "        verbose=0,\n",
    "        epochs=N_EPOCHS,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[callback],\n",
    "        validation_data=(x_val.values, None),\n",
    "    )\n",
    "\n",
    "    evaluation = {}\n",
    "    evaluation[\"train\"] = vae.evaluate(\n",
    "        x_train, vae.predict(x_train), verbose=0, return_dict=True\n",
    "    )\n",
    "    evaluation[\"val\"] = vae.evaluate(\n",
    "        x_val, vae.predict(x_val), verbose=0, return_dict=True\n",
    "    )\n",
    "    evaluation[\"test\"] = vae.evaluate(\n",
    "        x_test, vae.predict(x_test), verbose=0, return_dict=True\n",
    "    )\n",
    "\n",
    "    pd.DataFrame.from_dict(evaluation).reset_index(names=\"metric\").assign(\n",
    "        seed=seed\n",
    "    ).melt(\n",
    "        id_vars=[\"seed\", \"metric\"],\n",
    "        value_vars=[\"train\", \"val\", \"test\"],\n",
    "        var_name=\"split\",\n",
    "        value_name=\"score\",\n",
    "    ).assign(\n",
    "        model=model_kind\n",
    "    ).to_pickle(\n",
    "        results_path_model.joinpath(f\"metrics-seed-{seed:02d}.pkl\")\n",
    "    )\n",
    "\n",
    "    layer_outputs = [layer.output for layer in encoder.layers]\n",
    "    activation_model = Model(inputs=encoder.input, outputs=layer_outputs)\n",
    "\n",
    "    # only analyze informed and funnel layers\n",
    "    for layer_id in range(1, len(layer_outputs)):\n",
    "        if model_kind == \"ivae_kegg\":\n",
    "            if layer_id == 1:\n",
    "                colnames = kegg_circuit_names\n",
    "                layer_name = \"circuits\"\n",
    "            elif layer_id == 2:\n",
    "                colnames = kegg_pathway_names\n",
    "                layer_name = \"pathways\"\n",
    "            elif layer_id == (len(layer_outputs) - 1):\n",
    "                n_latents = len(kegg_pathway_names) // 2\n",
    "                colnames = [f\"latent_{i:02d}\" for i in range(n_latents)]\n",
    "                layer_name = \"funnel\"\n",
    "            else:\n",
    "                continue\n",
    "        elif model_kind == \"ivae_reactome\":\n",
    "            if layer_id == 1:\n",
    "                colnames = reactome_pathway_names\n",
    "                layer_name = \"pathways\"\n",
    "            elif layer_id == (len(layer_outputs) - 1):\n",
    "                n_latents = len(reactome_pathway_names) // 2\n",
    "                colnames = [f\"latent_{i:02d}\" for i in range(n_latents)]\n",
    "                layer_name == \"funnel\"\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            raise NotImplementedError(\"Model not yet implemented.\")\n",
    "\n",
    "        print(f\"encoding layer {layer_id}\")\n",
    "\n",
    "        encodings = get_activations(\n",
    "            act_model=activation_model,\n",
    "            layer_id=layer_id,\n",
    "            data=x_trans.apply(minmax_scale),\n",
    "        )\n",
    "        encodings = pd.DataFrame(encodings, index=x_trans.index, columns=colnames)\n",
    "        encodings[\"split\"] = \"train\"\n",
    "        encodings.loc[x_val.index, \"split\"] = \"val\"\n",
    "        encodings.loc[x_test.index, \"split\"] = \"test\"\n",
    "        encodings[\"layer\"] = layer_name\n",
    "        encodings[\"seed\"] = seed\n",
    "        encodings[\"model\"] = model_kind\n",
    "        encodings = encodings.merge(\n",
    "            obs[[\"cell_type\", \"condition\"]],\n",
    "            how=\"left\",\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "        )\n",
    "        encodings.to_pickle(\n",
    "            results_path_model.joinpath(\n",
    "                f\"encodings_layer-{layer_id:02d}_seed-{seed:02d}.pkl\"\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_img_file = results_path_model.joinpath(f\"architecture.{model_kind}.png\")\n",
    "keras.utils.plot_model(vae, to_file=dot_img_file, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_layer_names = [\"split\", \"layer\", \"seed\", \"cell_type\", \"condition\", \"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_metrics = [\n",
    "    pd.read_pickle(results_path_model.joinpath(f\"metrics-seed-{seed:02d}.pkl\"))\n",
    "    for seed in range(N_ITERS)\n",
    "]\n",
    "scores_metrics = pd.concat(scores_metrics, axis=0, ignore_index=True)\n",
    "scores_metrics.to_pickle(results_path_model.joinpath(\"scores_metrics.pkl\"))\n",
    "\n",
    "scores_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "sns.set_theme(context=\"paper\", font_scale=0.5, style=\"ticks\", rc=custom_params)\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=scores_metrics,\n",
    "    kind=\"violin\",\n",
    "    col=\"metric\",\n",
    "    height=2,\n",
    "    aspect=0.9,\n",
    "    sharey=False,\n",
    "    x=\"model\",\n",
    "    y=\"score\",\n",
    "    hue=\"split\",\n",
    "    split=False,\n",
    "    cut=0,\n",
    "    fill=False,\n",
    "    density_norm=\"count\",\n",
    "    inner=\"quart\",\n",
    "    linewidth=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_informed = {}\n",
    "\n",
    "for layer_id in range(1, n_encoding_layers + 1):\n",
    "    if results_path_model.joinpath(\n",
    "        f\"encodings_layer-{layer_id:02d}_seed-00.pkl\"\n",
    "    ).exists():\n",
    "        results_layer = [\n",
    "            pd.read_pickle(\n",
    "                results_path_model.joinpath(\n",
    "                    f\"encodings_layer-{layer_id:02d}_seed-{seed:02d}.pkl\"\n",
    "                )\n",
    "            )\n",
    "            for seed in range(N_ITERS)\n",
    "        ]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    scores_informed[layer_id] = {}\n",
    "    for split in [\"train\", \"test\", \"val\"]:\n",
    "        results = [\n",
    "            x.loc[x[\"split\"] == split].drop(non_layer_names, axis=1)\n",
    "            for x in results_layer\n",
    "        ]\n",
    "        scores_informed[layer_id][split] = []\n",
    "        for seed_i in range(N_ITERS):\n",
    "            for seed_j in range(seed_i + 1, N_ITERS):\n",
    "                scores_informed[layer_id][split].append(\n",
    "                    weightedtau(\n",
    "                        get_importances(data=results[seed_i], abs=True),\n",
    "                        get_importances(data=results[seed_j], abs=True),\n",
    "                    )[0]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_informed = (\n",
    "    pd.DataFrame.from_dict(scores_informed)\n",
    "    .melt(var_name=\"layer\", value_name=\"score\", ignore_index=False)\n",
    "    .reset_index(names=[\"split\"])\n",
    "    .explode(\"score\")\n",
    ")\n",
    "scores_informed[\"score\"] = scores_informed[\"score\"].astype(\"float\")\n",
    "scores_informed[\"model\"] = model_kind\n",
    "scores_informed.to_pickle(results_path_model.joinpath(\"scores_informed.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_informed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "sns.set_theme(context=\"paper\", font_scale=0.5, style=\"ticks\", rc=custom_params)\n",
    "plt.figure(figsize=(2, 2))\n",
    "sns.violinplot(\n",
    "    data=scores_informed,\n",
    "    x=\"layer\",\n",
    "    y=\"score\",\n",
    "    hue=\"split\",\n",
    "    split=False,\n",
    "    cut=0,\n",
    "    fill=False,\n",
    "    density_norm=\"count\",\n",
    "    inner=\"quart\",\n",
    "    linewidth=0.5,\n",
    ")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from multiprocessing import cpu_count\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "\n",
    "batch_size = 256 * cpu_count() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_scores = {}\n",
    "\n",
    "for layer_id in range(1, n_encoding_layers + 1):\n",
    "    if results_path_model.joinpath(\n",
    "        f\"encodings_layer-{layer_id:02d}_seed-00.pkl\"\n",
    "    ).exists():\n",
    "        results_layer = [\n",
    "            pd.read_pickle(\n",
    "                results_path_model.joinpath(\n",
    "                    f\"encodings_layer-{layer_id:02d}_seed-{seed:02d}.pkl\"\n",
    "                )\n",
    "            )\n",
    "            for seed in range(N_ITERS)\n",
    "        ]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    train_embeddings_lst = [\n",
    "        x.loc[(x[\"split\"] == \"train\") & (x[\"condition\"] == \"control\")]\n",
    "        for x in results_layer\n",
    "    ]\n",
    "    val_embeddings_lst = [\n",
    "        x.loc[(x[\"split\"] == \"val\") & (x[\"condition\"] == \"control\")]\n",
    "        for x in results_layer\n",
    "    ]\n",
    "    test_embeddings_lst = [\n",
    "        x.loc[(x[\"split\"] == \"test\") & (x[\"condition\"] == \"control\")]\n",
    "        for x in results_layer\n",
    "    ]\n",
    "\n",
    "    clust_scores[layer_id] = {}\n",
    "    clust_scores[layer_id][\"train\"] = []\n",
    "    clust_scores[layer_id][\"val\"] = []\n",
    "    clust_scores[layer_id][\"test\"] = []\n",
    "\n",
    "    for seed in range(N_ITERS):\n",
    "        y_train = train_embeddings_lst[seed][\"cell_type\"]\n",
    "        y_val = val_embeddings_lst[seed][\"cell_type\"]\n",
    "        y_test = test_embeddings_lst[seed][\"cell_type\"]\n",
    "\n",
    "        train_embeddings = train_embeddings_lst[seed].drop(non_layer_names, axis=1)\n",
    "        val_embeddings = val_embeddings_lst[seed].drop(non_layer_names, axis=1)\n",
    "        test_embeddings = test_embeddings_lst[seed].drop(non_layer_names, axis=1)\n",
    "\n",
    "        model = MiniBatchKMeans(n_clusters=y_train.nunique(), batch_size=batch_size)\n",
    "        model.fit(train_embeddings)\n",
    "        clust_scores[layer_id][\"train\"].append(\n",
    "            adjusted_mutual_info_score(y_train, model.labels_)\n",
    "        )\n",
    "        clust_scores[layer_id][\"val\"].append(\n",
    "            adjusted_mutual_info_score(y_val, model.predict(val_embeddings))\n",
    "        )\n",
    "        clust_scores[layer_id][\"test\"].append(\n",
    "            adjusted_mutual_info_score(y_test, model.predict(test_embeddings))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_scores = (\n",
    "    pd.DataFrame.from_dict(clust_scores)\n",
    "    .melt(var_name=\"layer\", value_name=\"score\", ignore_index=False)\n",
    "    .reset_index(names=[\"split\"])\n",
    "    .explode(\"score\")\n",
    ")\n",
    "clust_scores[\"score\"] = clust_scores[\"score\"].astype(\"float\")\n",
    "clust_scores[\"model\"] = model_kind\n",
    "clust_scores.to_pickle(results_path_model.joinpath(\"scores_clustering.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "sns.set_theme(context=\"paper\", font_scale=0.5, style=\"ticks\", rc=custom_params)\n",
    "plt.figure(figsize=(2, 2))\n",
    "sns.violinplot(\n",
    "    data=clust_scores,\n",
    "    x=\"layer\",\n",
    "    y=\"score\",\n",
    "    hue=\"split\",\n",
    "    split=False,\n",
    "    cut=0,\n",
    "    fill=False,\n",
    "    density_norm=\"count\",\n",
    "    inner=\"quart\",\n",
    "    linewidth=0.5,\n",
    ")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b4651b61dd9046e4bae09ab0c22b4cc207f37f5591f1d5dbc867d81958be0f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
